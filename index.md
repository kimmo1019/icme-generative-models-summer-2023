---
layout: default
---

# Introduction to Generative Models

Join us for the Generative Models workshop and unlock the fascinating world of Deep Generative Modeling. In this rapidly growing field of Machine Learning, you'll discover how computers can create intricate landscapes, generate images of non-existent humans, and produce stunning art. Deep Generative Models provide a paradigm shift from traditional discriminative models, allowing the creation of new content based on user input rather than classification.

During this workshop, you'll delve into the foundational concepts of Deep Generative Modeling, explore various types of models, and learn about their diverse applications in different fields. With a focus on Python, you'll gain hands-on experience in creating your own Deep Generative Models for various tasks. The workshop features engaging lectures, practical coding exercises, and insightful reviews to enhance your understanding. By the end of the workshop, you'll develop a clear comprehension of the underlying theory and concepts of Deep Generative Modeling. You'll explore different models such as Generative Adversarial Networks (GANs), Variational Auto-Encoders (VAEs), and Diffusion Models. Discover how these models are applied in academia, industry, and your own work. With hands-on coding experience in PyTorch, you'll be equipped to implement these models from scratch and apply them to your own applications. Join us and unleash the power of Deep Generative Modeling in the world of Machine Learning.

It is important to note that participants do not need to install Python or any other libraries before the workshop. The workshop will utilize Jupyter notebooks, and all the necessary code, exercises, and solutions will be shared online. A Google account will be required as the workshop will use Google Colab for sharing the notebooks.


## About the Instructor

![Aashwin Mishra](/assets/img/aashwin.png){:style="max-width:30%;"}

Aashwin Mishra is a Project Scientist at the Machine Learning Initiative at the National Accelerator Laboratory (SLAC). His research focuses on uncertainty quantification, probabilistic modeling, interpretability/explainability, and optimization across physics applications.

# Workshop Materials

## Pre-workshop Checklist

The workshop assumes that you have the requisite knowledge of: 

- Prior Experience in Python Programming: Participants should have prior experience in programming, particularly using Python. Familiarity with Python syntax, data structures, control flow, and the ability to write and execute Python code is essential for understanding and implementing generative models. Knowledge of common Python libraries used in deep learning, such as PyTorch, will also be beneficial.

- Understanding of Probability Theory and Linear Algebra: A solid understanding of probability theory is recommended. Participants should be familiar with basic probability concepts such as probability distributions, conditional probability, and expectations. Additionally, a foundational understanding of linear algebra, including concepts such as vectors, matrices, matrix operations, and vector spaces, is important for comprehending the underlying mathematics of generative models.

- Basic Experience with Deep Learning: Participants should have basic experience and knowledge of deep learning concepts. This includes understanding the fundamentals of training neural networks, common activation functions, loss functions, optimization algorithms (e.g., gradient descent), and the general workflow of developing deep learning models. The "Introduction to Deep Learning" workshop offered in the same series is mentioned as covering most of the required prerequisites, so attending that workshop beforehand is recommended.

## Schedule

#### Session 1 (Tuesday, August 9 1:00 PM - 4:00 PM PDT)

-[Recording of session 1](https://stanford.zoom.us/rec/share/RnyMtZprvqt5koJUADNoleea81GxBE_W5AR0-Cla3EXwfkFJes1jiGH4icVowfAI.BL2ezLklu15PzXoK?startTime=1660074060000)

-Review of basic ML concepts

-Overview of deep learning

-Coding a perceptron in numpy

-Understanding fully connected neural networks

-Coding fully connected neural networks in numpy

-Introduction to Torch

-Using the AD facilities in torch to train models

-Using the sub-modules in torch to define and train models
  
#### Session 2 (Wednesday, August 10 1:00 PM - 4:00 PM PDT)

-[Recording of session 2](https://stanford.zoom.us/rec/share/rWi9bweXG3QJvF7M1rURkEHcSn_kN2Cw7pK1SJjxpFJqnTg7hPnDG7-K41dG6kM0.Vq_VzePu5vP1HGJA?startTime=1660160664000)

-Understanding Convolutional Neural Networks

-Defining and Training CNNs in torch 

-Using GPUs for training

-Data Augmentation 

#### Google Colab notebooks

-[Linear Regression Exercise in Numpy:](https://colab.research.google.com/drive/1w0C62ikCOotfBJ5FbzQu4I3weu6viAmj?usp=sharing)

-[Solutions: Linear Regression Exercise in Numpy](https://colab.research.google.com/drive/1w0C62ikCOotfBJ5FbzQu4I3weu6viAmj?usp=sharing)

-[Shallow Neural Network in Numpy:](https://colab.research.google.com/drive/1mbquyEd_N_JMh8nTupbXgId1ArVZuP3L?usp=sharing)

-[Solutions: Shallow Neural Network in Numpy](https://colab.research.google.com/drive/1mbquyEd_N_JMh8nTupbXgId1ArVZuP3L?usp=sharing)

-[Introduction to Torch](https://colab.research.google.com/drive/1b1ifUhsdo7rYeUEKBjEQkWTgWX0EgEz6?usp=sharing)

-[My First Torch Model:](https://colab.research.google.com/drive/1GLihAAAmsz1Snqt2GLg55hSO0UQWBGLM?usp=sharing)

-[MNIST with an FCNN:](https://colab.research.google.com/drive/1Wp2jWYnZ50VWBPCVEkPemUcF3ohrxrct?usp=sharing)

-[CIFAR10 with CNNs:](https://colab.research.google.com/drive/1eZniJ3FW77cAy4U3cSieJPSq-ukMARPY?usp=sharing)

-[CIFAR10 with GPUs:](https://colab.research.google.com/drive/153nTZtmHENNTx-XLWw3kl41Shd-ZvXVJ?usp=sharing)

-[Data Augmentation for Computer Vision:](https://colab.research.google.com/drive/1Ug0STBPfwc0Q7YSBasliIJCC38y9pOVm?usp=sharing)
